{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11027e3-bf58-41ea-9246-9568b8772938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/config.py\n",
    "EXAM_ID = 5\n",
    "#MAX_IMAGES = 250\n",
    "MAX_IMAGES = 30\n",
    "ARXIV_BASE_URL = \"https://export.arxiv.org/pdf/\"\n",
    "MIN_IMAGE_AREA = 12_000   # important later\n",
    "VECTOR_DPI = 250\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da906641-e801-4560-b583-1b88e207483e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/download_all_pdfs.py\n",
    "\n",
    "import time\n",
    "import requests\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from PIL import Image\n",
    "\n",
    "# -----------------------------\n",
    "# Configuration\n",
    "# -----------------------------\n",
    "EXAM_ID = 5\n",
    "ARXIV_BASE_URL = \"https://export.arxiv.org/pdf/\"\n",
    "REQUEST_DELAY = 10       # seconds (arXiv friendly)\n",
    "MAX_RETRIES = 3\n",
    "MIN_PDF_SIZE = 5_000     # bytes\n",
    "BASE_DIR = Path(\"/Volumes/TEJASWI MS/NLP_examid_5_Tejaswi_Duptala\")\n",
    "#BASE_DIR = Path(\"/Users/tejaswiduptala/Desktop/NLP\")\n",
    "\n",
    "#BASE_DIR = Path.cwd()\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "PDF_DIR = DATA_DIR / \"pdfs\"\n",
    "LOG_DIR = BASE_DIR / \"outputs\" / \"logs\"\n",
    "PAPER_LIST_PATH = BASE_DIR / \"paper_list_5.txt\"\n",
    "OUTPUT_DIR = BASE_DIR / \"outputs\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "IMAGE_DIR = BASE_DIR / f\"images_{EXAM_ID}\"\n",
    "IMAGE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PDF_DIR.mkdir(parents=True, exist_ok=True)\n",
    "LOG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "DATASET_JSON_PATH = OUTPUT_DIR / \"dataset_5.json\"\n",
    "COUNTS_CSV_PATH = OUTPUT_DIR / \"paper_list_counts_5.csv\"\n",
    "\n",
    "# Gate keywords \n",
    "GATE_KEYWORDS = [\n",
    "    \"H\", \"X\", \"Y\", \"Z\", \"CNOT\", \"CZ\", \"SWAP\", \"CCNOT\", \"TOFFOLI\",\n",
    "    \"RX\", \"RY\", \"RZ\", \"T\", \"S\"\n",
    "]\n",
    "\n",
    "# Algorithm keywords \n",
    "ALGO_KEYWORDS = {\n",
    "    \"teleport\": \"Quantum Teleportation\",\n",
    "    \"grover\": \"Grover Search\",\n",
    "    \"fourier\": \"Quantum Fourier Transform\",\n",
    "    \"qft\": \"Quantum Fourier Transform\",\n",
    "    \"phase estimation\": \"Phase Estimation\",\n",
    "    \"shor\": \"Shor's Algorithm\",\n",
    "    \"vqe\": \"Variational Quantum Eigensolver\",\n",
    "    \"qaoa\": \"QAOA\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Logging\n",
    "# -----------------------------\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename=LOG_DIR / \"download_all.log\",\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\"\n",
    ")\n",
    "'''\n",
    "logging.getLogger().disabled = True\n",
    "'''\n",
    "\n",
    "def log(msg, logfile=None, level=logging.INFO):\n",
    "    print(msg)\n",
    "    logging.log(level, msg)\n",
    "    if logfile:\n",
    "        with open(LOG_DIR / logfile, \"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(msg + \"\\n\")\n",
    "\n",
    "def load_paper_list(path=PAPER_LIST_PATH):\n",
    "    \"\"\"Load arXiv paper IDs from paper_list_5.txt in given order.\"\"\"\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return [line.strip() for line in f if line.strip()]\n",
    "\n",
    "def normalize_arxiv_id(arxiv_id: str) -> str:\n",
    "    \"\"\"Normalize arXiv ID for URL usage (remove 'arXiv:' prefix).\"\"\"\n",
    "    arxiv_id = arxiv_id.strip()\n",
    "    if arxiv_id.lower().startswith(\"arxiv:\"):\n",
    "        arxiv_id = arxiv_id.split(\":\", 1)[1]\n",
    "    return arxiv_id\n",
    "\n",
    "# -----------------------------\n",
    "# PDF Downloader\n",
    "# -----------------------------\n",
    "SESSION = requests.Session()\n",
    "SESSION.headers.update({\"User-Agent\": \"NLP-QuantumCircuitDataset/1.0\"})\n",
    "\n",
    "def download_pdf(arxiv_id: str, timeout=30):\n",
    "    \"\"\"Download arXiv PDF with caching, retries, and rate limiting.\"\"\"\n",
    "    clean_id = normalize_arxiv_id(arxiv_id)\n",
    "    url = f\"{ARXIV_BASE_URL}{clean_id}.pdf\"\n",
    "    out_path = PDF_DIR / f\"{clean_id}.pdf\"\n",
    "\n",
    "    # Cache\n",
    "    if out_path.exists() and out_path.stat().st_size > MIN_PDF_SIZE:\n",
    "        log(f\"[CACHE] {clean_id}\")\n",
    "        return out_path\n",
    "\n",
    "    for attempt in range(1, MAX_RETRIES + 1):\n",
    "        log(f\"[REQUEST] ({attempt}/{MAX_RETRIES}) {clean_id}\")\n",
    "\n",
    "        try:\n",
    "            resp = SESSION.get(url, timeout=timeout, stream=True)\n",
    "            time.sleep(REQUEST_DELAY)\n",
    "\n",
    "            if resp.status_code != 200:\n",
    "                log(f\"[ERROR] HTTP {resp.status_code} for {clean_id}\", logfile=\"download_errors.log\")\n",
    "                resp.close()\n",
    "                continue\n",
    "\n",
    "            tmp_path = out_path.with_suffix(\".tmp\")\n",
    "            with open(tmp_path, \"wb\") as f:\n",
    "                for chunk in resp.iter_content(chunk_size=4096):\n",
    "                    if chunk:\n",
    "                        f.write(chunk)\n",
    "            resp.close()\n",
    "\n",
    "            if tmp_path.stat().st_size < MIN_PDF_SIZE:\n",
    "                log(f\"[ERROR] PDF too small for {clean_id}\", logfile=\"download_errors.log\")\n",
    "                tmp_path.unlink(missing_ok=True)\n",
    "                continue\n",
    "\n",
    "            tmp_path.rename(out_path)\n",
    "            log(f\"[SUCCESS] Saved {out_path.name}\")\n",
    "            return out_path\n",
    "\n",
    "        except Exception as e:\n",
    "            log(f\"[EXCEPTION] {clean_id}: {e}\", logfile=\"download_errors.log\")\n",
    "            time.sleep(REQUEST_DELAY)\n",
    "\n",
    "    log(f\"[FAILED] Could not download {clean_id}\", logfile=\"download_errors.log\")\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f66ab77-e7f1-476a-bd06-8320b152caa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_descriptions_for_figure(\n",
    "    full_text: str,\n",
    "    page_texts: list,\n",
    "    page_number: int,\n",
    "    figure_number: str | None,\n",
    "    window: int = 600\n",
    "):\n",
    "    \"\"\"\n",
    "    Memory-safe description extraction.\n",
    "    Operates ONLY on the current page text.\n",
    "    \"\"\"\n",
    "    if figure_number is None:\n",
    "        return [], []\n",
    "\n",
    "    page_text = dict(page_texts).get(page_number, \"\")\n",
    "    if not page_text:\n",
    "        return [], []\n",
    "\n",
    "    import re\n",
    "    pat = re.compile(\n",
    "        rf\"(fig\\.?|figure)\\s*{re.escape(str(figure_number))}\",\n",
    "        re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    m = pat.search(page_text)\n",
    "    if not m:\n",
    "        return [], []\n",
    "\n",
    "    start = max(0, m.start() - window)\n",
    "    end = min(len(page_text), m.end() + window)\n",
    "\n",
    "    snippet = page_text[start:end].strip()\n",
    "\n",
    "    # Map snippet into global text position (approximate, documented)\n",
    "    global_start = full_text.find(snippet)\n",
    "    if global_start == -1:\n",
    "        return [snippet], []\n",
    "\n",
    "    return [snippet], [[global_start, global_start + len(snippet)]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d919d9fd-8cb4-489d-9581-df5511ac445a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ertract full text \n",
    "def extract_full_text(pdf_path):\n",
    "    \"\"\"\n",
    "    Extract full text and per-page text from a PDF.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    full_text : str\n",
    "        Concatenated text of all pages.\n",
    "    page_texts : list of (page_number, page_text)\n",
    "        Page-level text used for raster classification.\n",
    "    \"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    full_text_pages = []\n",
    "    page_texts = []\n",
    "\n",
    "    for i, page in enumerate(doc):\n",
    "        text = page.get_text(\"text\")\n",
    "        clean = \" \".join(text.split())\n",
    "        page_number = i + 1\n",
    "        page_texts.append((page_number, clean))\n",
    "        full_text_pages.append(clean)\n",
    "\n",
    "    doc.close()\n",
    "\n",
    "    full_text = \"\\n\".join(full_text_pages)\n",
    "    return full_text, page_texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32911dc-6c42-418d-9a19-4fef91f47f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_pixmap_as_png(pixmap, filename: str, out_dir: Path):\n",
    "    try:\n",
    "        mode = \"RGB\" if pixmap.n < 4 else \"RGBA\"\n",
    "        img = Image.frombytes(mode, (pixmap.width, pixmap.height), pixmap.samples)\n",
    "    except Exception:\n",
    "        pix = fitz.Pixmap(fitz.csRGB, pixmap)\n",
    "        img = Image.frombytes(\"RGB\", (pix.width, pix.height), pix.samples)\n",
    "\n",
    "    out_path = out_dir / filename\n",
    "    img.save(out_path, format=\"PNG\")\n",
    "    return out_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d08cd3-90c2-4cba-9830-8e2e2831c7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rasster image\n",
    "def extract_images_from_pdf(pdf_path: Path, min_area: int = 12_000):\n",
    "    \"\"\"\n",
    "    Extract embedded raster images from a PDF, filtering out\n",
    "    tiny images (icons, equations, glyphs).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pdf_path : Path\n",
    "        Path to the PDF file.\n",
    "    min_area : int\n",
    "        Minimum on-page area (PDF coordinate space) an image\n",
    "        must occupy to be considered a valid candidate.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    List[dict]\n",
    "        Each dict contains:\n",
    "        - page_number : int (1-based)\n",
    "        - image_index : int (0-based index on that page)\n",
    "        - pixmap      : fitz.Pixmap\n",
    "        - rects       : List[fitz.Rect] (locations on page)\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    doc = fitz.open(pdf_path)\n",
    "\n",
    "    for page_idx, page in enumerate(doc):\n",
    "        page_number = page_idx + 1\n",
    "        image_list = page.get_images(full=True)\n",
    "\n",
    "        if not image_list:\n",
    "            continue\n",
    "\n",
    "        for img_idx, img_info in enumerate(image_list):\n",
    "            xref = img_info[0]\n",
    "\n",
    "            # Where does this image appear on the page?\n",
    "            rects = page.get_image_rects(xref)\n",
    "            if not rects:\n",
    "                continue\n",
    "\n",
    "            # Reject tiny on-page images (equations, icons)\n",
    "            max_rect_area = max(r.get_area() for r in rects)\n",
    "            if max_rect_area < min_area:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                pix = fitz.Pixmap(doc, xref)\n",
    "                results.append({\n",
    "                    \"page_number\": page_number,\n",
    "                    \"image_index\": img_idx,\n",
    "                    \"pixmap\": pix,\n",
    "                    \"rects\": rects\n",
    "                })\n",
    "            except Exception as e:\n",
    "                log(f\"[ERROR] Failed to extract image xref={xref} \"\n",
    "                    f\"on page {page_number}: {e}\",\n",
    "                    logfile=\"parsing_errors.log\")\n",
    "\n",
    "    doc.close()\n",
    "    log(f\"[INFO] Extracted {len(results)} raster image candidates from {pdf_path.name}\")\n",
    "    return results\n",
    "\n",
    "def is_raster_circuit_image(pixmap, page_text: str = \"\") -> bool:\n",
    "    \"\"\"\n",
    "    Conservative rule-based classifier for raster quantum circuit images.\n",
    "    High precision by requiring multiple independent signals.\n",
    "    \"\"\"\n",
    "\n",
    "    # ---------------------------\n",
    "    # 1. Geometry constraints\n",
    "    # ---------------------------\n",
    "    w, h = pixmap.width, pixmap.height\n",
    "    if w < 200 or h < 100:\n",
    "        return False\n",
    "\n",
    "    aspect = w / max(h, 1)\n",
    "    if aspect < 1.3:\n",
    "        return False\n",
    "\n",
    "    # ---------------------------\n",
    "    # 2. Reject plot-heavy pages\n",
    "    # ---------------------------\n",
    "    text = (page_text or \"\").lower()\n",
    "\n",
    "    PLOT_KEYWORDS = [\n",
    "        \"energy\", \"loss\", \"fidelity\", \"probability\",\n",
    "        \"iteration\", \"epoch\", \"accuracy\", \"temperature\",\n",
    "        \"distance\", \"spectrum\", \"histogram\", \"counts\"\n",
    "    ]\n",
    "    if any(k in text for k in PLOT_KEYWORDS):\n",
    "        return False\n",
    "\n",
    "    # ---------------------------\n",
    "    # 3. Circuit & gate evidence\n",
    "    # ---------------------------\n",
    "    CIRCUIT_KEYWORDS = [\n",
    "    \"quantum circuit\",\n",
    "    \"circuit diagram\",\n",
    "    \"quantum gate\",\n",
    "    \"gate sequence\",\n",
    "    \"quantum register\",\n",
    "    \"qubit\",\n",
    "    \"qubits\",\n",
    "\n",
    "    \"ansatz\",\n",
    "    \"variational circuit\",\n",
    "    \"parameterized circuit\",\n",
    "    \"parametrized circuit\",\n",
    "    \"layered circuit\",\n",
    "    \"hardware efficient\",\n",
    "\n",
    "    \"gate decomposition\",\n",
    "    \"circuit decomposition\",\n",
    "    \"compiled circuit\",\n",
    "    \"circuit compilation\",\n",
    "    \"mapped circuit\",\n",
    "    \"transpiled circuit\",\n",
    "\n",
    "    \"entangling gate\",\n",
    "    \"two-qubit gate\",\n",
    "    \"multi-qubit gate\",\n",
    "    \"controlled gate\",\n",
    "    \"control qubit\",\n",
    "    \"target qubit\",\n",
    "\n",
    "    \"measurement circuit\",\n",
    "    \"readout circuit\",\n",
    "    \"basis rotation\",\n",
    "    \"measurement basis\",\n",
    "\n",
    "    \"circuit schematic\",\n",
    "    \"schematic diagram\",\n",
    "    \"logic circuit\",\n",
    "    \"quantum logic\",\n",
    "    ]\n",
    "\n",
    "\n",
    "    GATE_TOKENS = [\n",
    "        \"rx\", \"ry\", \"rz\",\n",
    "        \"cnot\", \"cx\", \"cz\",\n",
    "        \"ccx\", \"ccnot\", \"toffoli\",\n",
    "        \"swap\", \"xx\", \"yy\", \"zz\"\n",
    "    ]\n",
    "\n",
    "    keyword_hits = sum(1 for k in CIRCUIT_KEYWORDS if k in text)\n",
    "    gate_hits = sum(1 for g in GATE_TOKENS if g in text)\n",
    "\n",
    "    if keyword_hits >= 2 and gate_hits >= 1:\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45253019-8fda-4e3e-8770-443394d24233",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import re\n",
    "\n",
    "def pil_from_pixmap(pix: fitz.Pixmap) -> Image.Image:\n",
    "    \"\"\"Convert fitz.Pixmap -> PIL Image safely.\"\"\"\n",
    "    if pix.n >= 4:\n",
    "        pix = fitz.Pixmap(fitz.csRGB, pix)\n",
    "    return Image.frombytes(\"RGB\", (pix.width, pix.height), pix.samples)\n",
    "\n",
    "#===========\n",
    "#model a\n",
    "#===========\n",
    "def horizontal_line_score(img: Image.Image) -> float:\n",
    "    \"\"\"\n",
    "    Measures how dominant horizontal lines are.\n",
    "    Circuits ‚Üí high\n",
    "    Plots ‚Üí low\n",
    "    \"\"\"\n",
    "    gray = np.array(img.convert(\"L\"))\n",
    "    edges = cv2.Canny(gray, 50, 150)\n",
    "\n",
    "    # Hough transform for lines\n",
    "    lines = cv2.HoughLinesP(\n",
    "        edges,\n",
    "        rho=1,\n",
    "        theta=np.pi/180,\n",
    "        threshold=100,\n",
    "        minLineLength=gray.shape[1] // 4,\n",
    "        maxLineGap=10\n",
    "    )\n",
    "\n",
    "    if lines is None:\n",
    "        return 0.0\n",
    "\n",
    "    horiz = 0\n",
    "    total = len(lines)\n",
    "\n",
    "    for l in lines:\n",
    "        x1, y1, x2, y2 = l[0]\n",
    "        if abs(y1 - y2) < 5:  # horizontal\n",
    "            horiz += 1\n",
    "\n",
    "    return horiz / max(total, 1)\n",
    "\n",
    "def is_vector_crop_candidate(img: Image.Image) -> bool:\n",
    "    \"\"\"Validate cropped rendered region is likely a circuit.\"\"\"\n",
    "    w, h = img.size\n",
    "    #if w < 300 or h < 120:\n",
    "    if w < 220 or h < 100:\n",
    "        return False\n",
    "\n",
    "    aspect = w / max(h, 1)\n",
    "    #if aspect < 1.2:\n",
    "    if aspect < 1.05:\n",
    "        return False\n",
    "\n",
    "    d = line_density_score(img)\n",
    "\n",
    "    # Too low => empty / whitespace\n",
    "    #if d < 0.01:\n",
    "    if d < 0.005:\n",
    "        return False\n",
    "\n",
    "    # Too high => solid plot / filled region\n",
    "    #if d > 0.35:\n",
    "    if d > 0.40:\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "#===========\n",
    "#ocr based model b\n",
    "#===========\n",
    "def ocr_text_from_image(img: Image.Image) -> str:\n",
    "    \"\"\"\n",
    "    Extract text from image using OCR.\n",
    "    Used only for rejection, never sole acceptance.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        text = pytesseract.image_to_string(img)\n",
    "        return text.lower()\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "def line_density_score(img: Image.Image) -> float:\n",
    "    \"\"\"\n",
    "    Fraction of dark pixels.\n",
    "    Circuits ‚Üí low\n",
    "    Plots ‚Üí high\n",
    "    \"\"\"\n",
    "    gray = np.array(img.convert(\"L\"))\n",
    "    return np.mean(gray < 160)\n",
    "def strong_horizontal_wire_count(img: Image.Image) -> int:\n",
    "    \"\"\"\n",
    "    Count long horizontal lines (qubit wires).\n",
    "    \"\"\"\n",
    "    gray = np.array(img.convert(\"L\"))\n",
    "    edges = cv2.Canny(gray, 50, 150)\n",
    "\n",
    "    lines = cv2.HoughLinesP(\n",
    "        edges,\n",
    "        rho=1,\n",
    "        theta=np.pi / 180,\n",
    "        threshold=120,\n",
    "        minLineLength=int(gray.shape[1] * 0.6),\n",
    "        maxLineGap=5\n",
    "    )\n",
    "\n",
    "    if lines is None:\n",
    "        return 0\n",
    "\n",
    "    return sum(\n",
    "        abs(l[0][1] - l[0][3]) < 4\n",
    "        for l in lines\n",
    "    )\n",
    "\n",
    "#=========\n",
    "#common for both models\n",
    "#=========\n",
    "def horizontal_band_count(\n",
    "    img: Image.Image,\n",
    "    percentile: float = 95,\n",
    "    min_peaks: int = 6) -> int:\n",
    "    \"\"\"\n",
    "    Count horizontal intensity transitions (parallel bands).\n",
    "    Circuits ‚Üí many bands\n",
    "    Plots/text ‚Üí few\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = np.array(img.convert(\"L\"))\n",
    "\n",
    "    # Mean intensity per row\n",
    "    row_mean = gray.mean(axis=1)\n",
    "\n",
    "    # Row-to-row intensity change\n",
    "    diff = np.abs(np.diff(row_mean))\n",
    "\n",
    "    # Adaptive threshold\n",
    "    thresh = np.percentile(diff, percentile)\n",
    "\n",
    "    # Count significant transitions\n",
    "    peaks = np.where(diff > thresh)[0]\n",
    "\n",
    "    return len(peaks)\n",
    "\n",
    "def vertical_line_score(img: Image.Image) -> float:\n",
    "    import cv2\n",
    "    import numpy as np\n",
    "\n",
    "    gray = np.array(img.convert(\"L\"))\n",
    "    edges = cv2.Canny(gray, 50, 150)\n",
    "\n",
    "    lines = cv2.HoughLinesP(\n",
    "        edges,\n",
    "        rho=1,\n",
    "        theta=np.pi / 180,\n",
    "        threshold=100,\n",
    "        minLineLength=gray.shape[0] // 4,\n",
    "        maxLineGap=10\n",
    "    )\n",
    "\n",
    "    if lines is None:\n",
    "        return 0.0\n",
    "\n",
    "    vert = 0\n",
    "    total = len(lines)\n",
    "\n",
    "    for l in lines:\n",
    "        x1, y1, x2, y2 = l[0]\n",
    "        if abs(x1 - x2) < 5:  # vertical\n",
    "            vert += 1\n",
    "\n",
    "    return vert / max(total, 1)\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def small_box_count(\n",
    "    img: Image.Image,\n",
    "    min_area_ratio: float = 0.0003,\n",
    "    max_area_ratio: float = 0.02,\n",
    "    aspect_tol: float = 0.35\n",
    ") -> int:\n",
    "    \"\"\"\n",
    "    Count small rectangular gate-like boxes.\n",
    "\n",
    "    Circuits ‚Üí many small rectangles\n",
    "    Plots/text ‚Üí near zero\n",
    "    \"\"\"\n",
    "\n",
    "    gray = np.array(img.convert(\"L\"))\n",
    "\n",
    "    # Binary image\n",
    "    _, bw = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(\n",
    "        bw, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
    "    )\n",
    "\n",
    "    h, w = gray.shape\n",
    "    img_area = h * w\n",
    "\n",
    "    count = 0\n",
    "    for c in contours:\n",
    "        x, y, cw, ch = cv2.boundingRect(c)\n",
    "        area = cw * ch\n",
    "\n",
    "        # Area filter\n",
    "        if area < min_area_ratio * img_area:\n",
    "            continue\n",
    "        if area > max_area_ratio * img_area:\n",
    "            continue\n",
    "\n",
    "        # Aspect ratio (rectangular)\n",
    "        ar = cw / max(ch, 1)\n",
    "        if abs(ar - 1.0) > aspect_tol:\n",
    "            continue\n",
    "\n",
    "        count += 1\n",
    "\n",
    "    return count\n",
    "\n",
    "#===================\n",
    "#passage images removal\n",
    "#===================\n",
    "\n",
    "def is_text_page(img: Image.Image) -> bool:\n",
    "    \"\"\"\n",
    "    Detect crops that are mostly text / equations / section headers,\n",
    "    not diagrams. This is intentionally aggressive.\n",
    "    \"\"\"\n",
    "    w, h = img.size\n",
    "\n",
    "    ocr = ocr_text_from_image(img)\n",
    "    words = ocr.split()\n",
    "    word_count = len(words)\n",
    "\n",
    "    d = line_density_score(img)\n",
    "    boxes = small_box_count(img)\n",
    "    wires = strong_horizontal_wire_count(img)\n",
    "\n",
    "    # 0) Very thin horizontal strips with words ‚Üí header/footer line\n",
    "    if h < 220 and word_count >= 3:\n",
    "        return True\n",
    "\n",
    "    # 1) Paragraphs or equations: many words, almost no boxes/wires\n",
    "    if word_count >= 8 and wires <= 2 and boxes <= 3:\n",
    "        return True\n",
    "\n",
    "    # 2) Section headers: few words, almost no structure, very low density\n",
    "    if 2 <= word_count <= 12 and wires == 0 and boxes <= 1 and d < 0.18:\n",
    "        return True\n",
    "\n",
    "    # 3) Medium density, no wires, few boxes ‚Üí text/equations\n",
    "    if 0.05 < d < 0.35 and wires == 0 and boxes <= 2 and word_count >= 3:\n",
    "        return True\n",
    "\n",
    "    # 4) OCR failed (no words), geometry looks like a text line\n",
    "    if word_count == 0 and wires == 0 and boxes <= 1 and d < 0.25 and h < 220:\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "# ==================\n",
    "# GRAPH REJECTION \n",
    "# ==================\n",
    "\n",
    "# ============================================================\n",
    "# MODEL A ‚Äì STRUCTURAL VECTOR DETECTOR\n",
    "# ============================================================\n",
    "\n",
    "def is_vector_circuit_model_A(\n",
    "    descriptions,\n",
    "    pil_img: Image.Image,\n",
    "    max_words: int = 12,\n",
    "    min_bands: int = 6,\n",
    "    min_horiz_ratio: float = 0.55,\n",
    "    min_boxes: int = 3,\n",
    "    max_boxes: int = 40,   # üî• NEW\n",
    ") -> bool:\n",
    "    \"\"\"\n",
    "    Robust vector quantum circuit classifier.\n",
    "    \"\"\"\n",
    "    \n",
    "    if pil_img.width < 300 or pil_img.height < 120:\n",
    "        return False\n",
    "\n",
    "    if pil_img is None:\n",
    "        return False\n",
    "\n",
    "    #  Visual sanity\n",
    "    if not is_vector_crop_candidate(pil_img):\n",
    "        return False\n",
    "\n",
    "    # Parallel wires\n",
    "    band_count = horizontal_band_count(pil_img)\n",
    "    if band_count < min_bands:\n",
    "        return False\n",
    "\n",
    "    #  Horizontal dominance\n",
    "    if horizontal_line_score(pil_img) < min_horiz_ratio:\n",
    "        return False\n",
    "\n",
    "    # Gate box structure (KEY FIX)\n",
    "    box_count = small_box_count(pil_img)\n",
    "    if not (min_boxes <= box_count <= max_boxes):\n",
    "        return False\n",
    "\n",
    "    # Caption-based rejection\n",
    "    text = \" \".join(descriptions).lower().strip()\n",
    "    if text:\n",
    "        if len(text.split()) > max_words:\n",
    "            return False\n",
    "\n",
    "        REJECT_TERMS = [\n",
    "            \"plot\",\"plot shows\", \"energy\", \"probability\", \"curve\",\n",
    "            \"iterations\", \"accuracy\", \"loss\",\n",
    "            \"graph\", \"chart\"\n",
    "        ]\n",
    "        if any(t in text for t in REJECT_TERMS):\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "# ============================================================\n",
    "# MODEL B ‚Äì OCR + WIRE DETECTOR\n",
    "# ============================================================\n",
    "\n",
    "def is_vector_circuit_model_B(\n",
    "    img: Image.Image,\n",
    "    caption_text: str = \"\",\n",
    ") -> bool:\n",
    "    \"\"\"\n",
    "    Combined Model B:\n",
    "    - STRICT branch (close to your original robust settings)\n",
    "    - SOFT branch (more permissive for smaller / lighter circuits)\n",
    "    - Shared OCR + caption-based graph/text rejection.\n",
    "    \"\"\"\n",
    "\n",
    "    # ---------- 1) OCR + caption filter (shared) ----------\n",
    "    ocr_text  = ocr_text_from_image(img)\n",
    "    ocr_words = ocr_text.split()\n",
    "    ocr_lower = ocr_text.lower()\n",
    "    cap_lower = caption_text.lower()\n",
    "\n",
    "    # Hard reject clear graph-like / training-like captions\n",
    "    HARD_REJECT_TERMS = [\n",
    "        \"plot\", \"plot shows\", \"graph\", \"chart\", \"curve\",\n",
    "        \"spectrum\", \"histogram\", \"time series\", \"counts\",\n",
    "        \"accuracy\", \"loss\", \"probability\",\n",
    "        \"distribution\", \"training\", \"iterations\",\n",
    "        \"mean\", \"variance\", \"error rate\", \"fidelity\"\n",
    "    ]\n",
    "    if any(t in ocr_lower for t in HARD_REJECT_TERMS):\n",
    "        return False\n",
    "    if any(t in cap_lower for t in HARD_REJECT_TERMS):\n",
    "        return False\n",
    "\n",
    "    wire_count = strong_horizontal_wire_count(img)\n",
    "    box_count  = small_box_count(img)\n",
    "    density    = line_density_score(img)\n",
    "    vscore     = vertical_line_score(img)\n",
    "\n",
    "    if density > 0.35:\n",
    "        return False\n",
    "\n",
    "    def strict_branch() -> bool:\n",
    "        max_ocr_words = 30\n",
    "        max_density   = 0.22\n",
    "        min_wires     = 4\n",
    "        min_boxes     = 4\n",
    "\n",
    "        if len(ocr_words) > max_ocr_words:\n",
    "            return False\n",
    "        if density > max_density:\n",
    "            return False\n",
    "\n",
    "        signals = 0\n",
    "        signals += wire_count >= min_wires\n",
    "        signals += box_count  >= min_boxes\n",
    "        signals += vscore > 0.15\n",
    "        signals += density < max_density\n",
    "\n",
    "        return signals >= 3\n",
    "\n",
    "    # ---------- 4) SOFT branch (more permissive) ----------\n",
    "    def soft_branch() -> bool:\n",
    "        max_ocr_words = 60\n",
    "        max_density   = 0.30\n",
    "        min_wires     = 2\n",
    "        min_boxes     = 2\n",
    "\n",
    "        if len(ocr_words) > max_ocr_words and \"circuit\" not in ocr_lower:\n",
    "            return False\n",
    "        if density > max_density:\n",
    "            return False\n",
    "\n",
    "        signals = 0\n",
    "        signals += wire_count >= min_wires\n",
    "        signals += box_count  >= min_boxes\n",
    "        # in circuits vertical lines should not dominate like axes\n",
    "        signals += vscore < 0.30\n",
    "\n",
    "        return signals >= 2\n",
    "\n",
    "    # ---------- 5) Final decision ----------\n",
    "    return strict_branch() or soft_branch()\n",
    "\n",
    "\n",
    "\n",
    "#=================\n",
    "#merging\n",
    "#==================\n",
    "\n",
    "#2 30%\n",
    "def is_vector_circuit_final(img: Image.Image, descriptions: list[str]) -> bool:\n",
    "    \"\"\"\n",
    "    Final decision for vector circuits.\n",
    "    Uses a soft scoring rule + the two specialist models.\n",
    "    \"\"\"\n",
    "    caption_text = \" \".join(descriptions)\n",
    "\n",
    "    # 1) Hard rejections\n",
    "    if is_definitely_graph(img,caption_text):\n",
    "        return False\n",
    "    \n",
    "    if is_text_page(img):\n",
    "        return False\n",
    "    # 2) Geometry features\n",
    "    h = horizontal_line_score(img)\n",
    "    v = vertical_line_score(img)\n",
    "    d = line_density_score(img)\n",
    "    bands = horizontal_band_count(img)\n",
    "    wires = strong_horizontal_wire_count(img)\n",
    "    boxes = small_box_count(img)\n",
    "\n",
    "    score = 0\n",
    "    if h >= 0.6:   # horizontal structure\n",
    "        score += 1\n",
    "    if v <= 0.30:  # not too many long verticals\n",
    "        score += 1\n",
    "    if d <= 0.35:  # not super dense / filled\n",
    "        score += 1\n",
    "    if bands >= 4:\n",
    "        score += 1\n",
    "    if wires >= 2:\n",
    "        score += 1\n",
    "    if boxes >= 2:\n",
    "        score += 1\n",
    "\n",
    "    # require at least 3 independent \"circuit-like\" signals\n",
    "    if score < 3:\n",
    "        return False\n",
    "\n",
    "    # 3) Specialist models (A + B)\n",
    "    ok_A = is_vector_circuit_model_A(\n",
    "        descriptions=descriptions,\n",
    "        pil_img=img\n",
    "    )\n",
    "\n",
    "    ok_B = is_vector_circuit_model_B(\n",
    "        img=img,\n",
    "        caption_text=\" \".join(descriptions)\n",
    "    )\n",
    "\n",
    "    # If either model likes it, accept.\n",
    "    return ok_A or ok_B\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178f88e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph handling \n",
    "GRAPH_TERMS = [\n",
    "    \"accuracy\", \"loss\", \"probability\", \"iterations\",\n",
    "    \"distribution\", \"fidelity\", \"mean\", \"variance\",\n",
    "    \"plot\", \"plot shows\", \"graph\", \"chart\", \"curve\",\n",
    "    \"histogram\", \"spectrum\"\n",
    "]\n",
    "\n",
    "GRAPH_CAPTION_KEYWORDS = [\n",
    "    # very graph-ish phrases\n",
    "    \"as a function of\",\n",
    "    \"dependence of\",\n",
    "    \"dependence on\",\n",
    "    \"versus\",\n",
    "    \"vs.\",\n",
    "    \"vs \",\n",
    "    \"variation of\",\n",
    "    \"evolution of\",\n",
    "    \"time trace\",\n",
    "    \"histogram\",\n",
    "    \"spectrum\",\n",
    "    \"spectra\",\n",
    "    \"density of states\",\n",
    "    \"probability distribution\",\n",
    "    \"probability density\",\n",
    "    \"power spectrum\",\n",
    "    \"fourier spectrum\",\n",
    "    \"band structure\",\n",
    "    \"correlation function\",\"plot\", \"plot shows\", \"graph\", \"chart\", \"curve\",\n",
    "    \"histogram\", \"spectrum\",\n",
    "\n",
    "    # axes-ish words that almost never describe a circuit\n",
    "    \"real part\",\"imaginary\",\"imaginary part\",\n",
    "    \"imaginary part\",\n",
    "    \"re[\",\n",
    "    \"im[\",\n",
    "    \"x-axis\",\n",
    "    \"y-axis\",\n",
    "\n",
    "    # physics-style labels that show up in your examples\n",
    "    \"re(œá\", \"im(œá\", \"œá(\",  # chi plots\n",
    "    \"v_d/v_s\", \"v_d / v_s\",\n",
    "    \"log scale\",\n",
    "]\n",
    "\n",
    "def caption_looks_like_graph(descriptions: list[str]) -> bool:\n",
    "    \"\"\"\n",
    "    Decide if the *caption text* is clearly talking about a graph/plot.\n",
    "\n",
    "    We keep this pretty strict so that we don't kill real circuit figures.\n",
    "    \"\"\"\n",
    "    if not descriptions:\n",
    "        return False\n",
    "\n",
    "    text = \" \".join(descriptions).lower()\n",
    "\n",
    "    # Strong, almost-plot-only phrases\n",
    "    for kw in GRAPH_CAPTION_KEYWORDS:\n",
    "        if kw in text:\n",
    "            return True\n",
    "\n",
    "    # Common pattern: \"X vs Y\"\n",
    "    import re\n",
    "    if re.search(r\"\\bvs\\.?\\b\", text):\n",
    "        return True\n",
    "\n",
    "    # Very typical sentence for plots:\n",
    "    # \"Figure N shows ... as a function of ...\"\n",
    "    if \"as a function of\" in text:\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "def is_definitely_graph(img: Image.Image, caption_text: str = \"\") -> bool:\n",
    "    \"\"\"\n",
    "    Graph / plot detector using OCR + geometry + optional caption text.\n",
    "    \"\"\"\n",
    "\n",
    "    # ---------- 0) Caption-based test ----------\n",
    "    # If the caption screams \"graph\", bail out immediately.\n",
    "    if caption_text:\n",
    "        if caption_looks_like_graph([caption_text]):\n",
    "            return True\n",
    "\n",
    "\n",
    "    # ---------- 1) Textual hints (OCR) ----------\n",
    "    ocr = ocr_text_from_image(img).lower()\n",
    "    if any(t in ocr for t in GRAPH_TERMS):\n",
    "        return True\n",
    "\n",
    "    # ---------- 2) Geometry ----------\n",
    "    d  = line_density_score(img)        # fraction of dark pixels\n",
    "    h  = horizontal_line_score(img)     # fraction of long horizontal lines\n",
    "    v  = vertical_line_score(img)       # fraction of long vertical lines\n",
    "    bx = small_box_count(img)           # gate-like rectangles\n",
    "    bands = horizontal_band_count(img)  # horizontal intensity bands\n",
    "\n",
    "    # Heuristic:\n",
    "    # - graphs: some horizontals + some verticals, not too boxy\n",
    "    # - circuits: mostly horizontals, very few verticals, many boxes\n",
    "\n",
    "    # (a) Classic ‚Äúaxes + curves‚Äù look\n",
    "    if (\n",
    "        h < 0.85 and         # horizontals not overwhelmingly dominant\n",
    "        v > 0.18 and         # clear vertical structure (y-axis, grid)\n",
    "        bx <= 3 and          # almost no small boxes (unlike gates)\n",
    "        d > 0.15 and         # not extremely sparse\n",
    "        bands >= 5           # several horizontal bands across the plot area\n",
    "    ):\n",
    "        return True\n",
    "\n",
    "    # (b) Very dense figures with grid-like structure & few boxes\n",
    "    if (\n",
    "        d > 0.30 and         # dense\n",
    "        v > 0.15 and\n",
    "        bx <= 2\n",
    "    ):\n",
    "        return True\n",
    "\n",
    "    # otherwise: not confidently a graph\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3f8906",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def is_text_strip(img: Image.Image) -> bool:\n",
    "    \"\"\"\n",
    "    Detect wide, thin crops that are basically just text lines / headings.\n",
    "\n",
    "    This is intentionally aggressive: we *prefer* to reject too many\n",
    "    rather than keep paragraphs as 'figures'.\n",
    "    \"\"\"\n",
    "    w, h = img.size\n",
    "    if w == 0 or h == 0:\n",
    "        return True\n",
    "\n",
    "    aspect = w / float(h)\n",
    "\n",
    "    ocr = ocr_text_from_image(img)\n",
    "    words = ocr.split()\n",
    "    word_count = len(words)\n",
    "\n",
    "    d = line_density_score(img)\n",
    "    boxes = small_box_count(img)\n",
    "    wires = strong_horizontal_wire_count(img)\n",
    "\n",
    "    # --- 1) Very wide & thin with some words  -> header/footer/line of text\n",
    "    if aspect > 4.0 and h < 220 and word_count >= 3:\n",
    "        return True\n",
    "\n",
    "    # --- 2) Paragraph-ish: several words, no wires, almost no boxes\n",
    "    if word_count >= 5 and wires <= 0 and boxes <= 1:\n",
    "        return True\n",
    "\n",
    "    # --- 3) Medium density, no wires, few boxes  -> equations / text\n",
    "    if 0.05 < d < 0.35 and wires == 0 and boxes <= 2 and word_count >= 3:\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "FIG_CAPTION_RE = re.compile(\n",
    "    r\"(fig\\.?|figure)\\s*\\.?\\s*(\\d+(?:\\.\\d+)?)\",\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "def extract_vector_circuit_images(pdf_path, full_text, page_texts, dpi=120):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    zoom = dpi / 72\n",
    "    mat = fitz.Matrix(zoom, zoom)\n",
    "\n",
    "    page_text_dict = dict(page_texts)\n",
    "\n",
    "    for page_idx in range(len(doc)):\n",
    "        page = doc[page_idx]\n",
    "        page_number = page_idx + 1\n",
    "        page_text = page_text_dict.get(page_number, \"\")\n",
    "\n",
    "        # Only pages that even mention a figure\n",
    "        low_page_text = page_text.lower()\n",
    "        if \"fig\" not in low_page_text and \"figure\" not in low_page_text:\n",
    "            continue\n",
    "        #if \"fig\" not in page_text and \"figure\" not in page_text:\n",
    "         #   continue\n",
    "\n",
    "        caption_rect = None\n",
    "        figure_number = None\n",
    "\n",
    "        # ---- find caption block + parse figure number ----\n",
    "        for block in page.get_text(\"blocks\"):\n",
    "            raw_txt = (block[4] or \"\")\n",
    "            m = FIG_CAPTION_RE.search(raw_txt)\n",
    "            if m:\n",
    "                figure_number = m.group(2)      # e.g. \"2\" or \"3.1\"\n",
    "                caption_rect = fitz.Rect(block[:4])\n",
    "                break\n",
    "\n",
    "        if caption_rect is None:\n",
    "            # no recognizable caption, skip page\n",
    "            continue\n",
    "\n",
    "        page_rect = page.rect\n",
    "        crop_height = 0.35 * page_rect.height\n",
    "\n",
    "        clip = fitz.Rect(\n",
    "            page_rect.x0,\n",
    "            max(page_rect.y0, caption_rect.y0 - crop_height),\n",
    "            page_rect.x1,\n",
    "            caption_rect.y0\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            pix = page.get_pixmap(matrix=mat, clip=clip, alpha=False)\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "        # size sanity\n",
    "        if pix.width < 300 or pix.height < 150:\n",
    "            continue\n",
    "\n",
    "       \n",
    "        pil_img = pil_from_pixmap(pix)\n",
    "        #if is_text_strip(pil_img) or is_definitely_graph(pil_img):\n",
    "         #   continue\n",
    "        # strong early rejections\n",
    "        #if is_text_page(pil_img): \n",
    "        #    continue\n",
    "\n",
    "        #if is_text_strip(pil_img):\n",
    "         #   continue\n",
    "\n",
    "        #descriptions, positions = find_descriptions_for_figure(\n",
    "         #   full_text, page_texts, page_number, figure_number)\n",
    "        descriptions, positions = find_descriptions_for_figure(\n",
    "            full_text=full_text,\n",
    "            page_texts=page_texts,\n",
    "            page_number=page_number,\n",
    "            figure_number=figure_number\n",
    "        )\n",
    "\n",
    "\n",
    "        yield {\n",
    "            \"page_number\": page_number,\n",
    "            \"figure_number\": figure_number,\n",
    "            \"pixmap\": pix,\n",
    "            \"descriptions\": descriptions,\n",
    "            \"positions\": positions,\n",
    "        }\n",
    "\n",
    "    doc.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe32ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#meta data processing\n",
    "#FIG_REGEX = re.compile(r\"\\b(fig\\.?|figure)\\s*\\.?\\s*(\\d+(\\.\\d+)?)\\b\", re.IGNORECASE)\n",
    "def semantic_info_from_image(pixmap, descriptions):\n",
    "    \"\"\"\n",
    "    Use OCR + textual descriptions to infer gates and quantum problem.\n",
    "    Called from both raster and vector pipelines.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pixmap : fitz.Pixmap\n",
    "        Image data as extracted from the PDF.\n",
    "    descriptions : list[str]\n",
    "        Figure captions / local descriptions (may be empty).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    gates : list[str]\n",
    "    problem : str\n",
    "    \"\"\"\n",
    "    img = pil_from_pixmap(pixmap)\n",
    "    ocr_text = ocr_text_from_image(img)\n",
    "\n",
    "    gates = detect_quantum_gates(descriptions, ocr_text=ocr_text)\n",
    "    problem = detect_quantum_problem(descriptions, ocr_text=ocr_text)\n",
    "\n",
    "    return gates, problem\n",
    "\n",
    "FIG_REGEX = re.compile(\n",
    "    r\"(fig|figure)\\s*\\.?\\s*(\\d+(\\.\\d+)?)\",\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "def infer_figure_number_from_page(page_text: str, local_image_index: int):\n",
    "\n",
    "    \"\"\"\n",
    "    Infer the figure number for a given image on a page.\n",
    "\n",
    "    Strategy\n",
    "    --------\n",
    "    1. Parse all occurrences of 'Fig. X' / 'FIG. X' / 'Figure X' in the page text.\n",
    "    2. Assume that the N-th extracted image on the page corresponds to the\n",
    "       N-th 'Fig.' occurrence in the text (0-based indexing).\n",
    "    3. If the image index exceeds the number of figure mentions, fall back\n",
    "       to the last figure mention on that page.\n",
    "    4. If no figure mention is found at all, return None.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    page_text : str\n",
    "        The text content of the page (we extracted this via extract_full_text()).\n",
    "    local_image_index : int\n",
    "        0-based index of the image on that page, as returned by extract_images_from_pdf().\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str or None\n",
    "        The inferred figure number (e.g., '2', '3.1') or None if no figure\n",
    "        reference could be found.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    This method is heuristic and may misalign images and figure numbers in\n",
    "    papers with very complex layouts. We document this limitation in the report.\n",
    "    \"\"\"\n",
    "    matches = list(FIG_REGEX.finditer(page_text))\n",
    "    if not matches:\n",
    "        # No figure references on this page\n",
    "        return None\n",
    "\n",
    "    # If we have at least as many figure mentions as images,\n",
    "    # map image index directly to figure mention index.\n",
    "    if local_image_index < len(matches):\n",
    "        m = matches[local_image_index]\n",
    "        fig_num = m.group(2)  # '2' or '3.1'\n",
    "        return fig_num\n",
    "\n",
    "    # Fallback: more images than 'Fig.' mentions,\n",
    "    # return the last figure number on this page.\n",
    "    last_match = matches[-1]\n",
    "    return last_match.group(2)\n",
    "\n",
    "\n",
    "BASE_GATES = [\n",
    "    \"H\", \"X\", \"Y\", \"Z\",\n",
    "    \"RX\", \"RY\", \"RZ\",\n",
    "    \"CNOT\", \"CZ\", \"SWAP\",\n",
    "    \"T\", \"S\",\n",
    "    \"TOFFOLI\"\n",
    "]\n",
    "# Strong multi-qubit / parameterized gates\n",
    "STRONG_GATES = {\n",
    "    \"CNOT\", \"CZ\", \"SWAP\",\n",
    "    \"TOFFOLI\", \"CCNOT\",\n",
    "    \"RX\", \"RY\", \"RZ\"\n",
    "}\n",
    "\n",
    "GATE_SYNONYMS = {\n",
    "    \"CX\": \"CNOT\",\n",
    "    \"C-X\": \"CNOT\",\n",
    "    \"C X\": \"CNOT\",\n",
    "    \"CCX\": \"TOFFOLI\",\n",
    "    \"CCNOT\": \"TOFFOLI\"\n",
    "}\n",
    "\n",
    "def normalize_gate_token(token: str) -> str:\n",
    "    token = token.upper().strip()\n",
    "\n",
    "    token = token.replace(\"R_X\", \"RX\").replace(\"R_Y\", \"RY\").replace(\"R_Z\", \"RZ\")\n",
    "    token = token.replace(\"R X\", \"RX\").replace(\"R Y\", \"RY\").replace(\"R Z\", \"RZ\")\n",
    "\n",
    "    if token in GATE_SYNONYMS:\n",
    "        token = GATE_SYNONYMS[token]\n",
    "\n",
    "    token = token.replace(\"‚Ä†\", \"\")\n",
    "\n",
    "    return token if token in BASE_GATES else \"\"\n",
    "\n",
    "def detect_quantum_gates(descriptions, ocr_text=None):\n",
    "    combined = \" \".join(descriptions) if descriptions else \"\"\n",
    "    if ocr_text:\n",
    "        combined += \" \" + ocr_text\n",
    "\n",
    "    combined_upper = combined.upper()\n",
    "    tokens = re.split(r\"[^A-Z0-9_]+\", combined_upper)\n",
    "\n",
    "    gates_found = set()\n",
    "\n",
    "    for tok in tokens:\n",
    "        gate = normalize_gate_token(tok)\n",
    "        if gate:\n",
    "            gates_found.add(gate)\n",
    "\n",
    "    extra_patterns = [\n",
    "        r\"\\bC\\-X\\b\", r\"\\bC X\\b\",\n",
    "        r\"\\bCX\\b\", r\"\\bCCX\\b\", r\"\\bCCNOT\\b\",\n",
    "        r\"\\bR_X\\b\", r\"\\bR_Y\\b\", r\"\\bR_Z\\b\"\n",
    "    ]\n",
    "\n",
    "    for pat in extra_patterns:\n",
    "        for m in re.finditer(pat, combined_upper):\n",
    "            gate = normalize_gate_token(m.group(0))\n",
    "            if gate:\n",
    "                gates_found.add(gate)\n",
    "\n",
    "    return sorted(gates_found)\n",
    "\n",
    "# ============================================================\n",
    "# 2. QUANTUM PROBLEM DETECTION (2.3.6)\n",
    "# ============================================================\n",
    "\n",
    "PROBLEM_PATTERNS = [\n",
    "    (\"Quantum Teleportation\", [\n",
    "        r\"\\bquantum\\s+teleportation\\b\",\n",
    "        r\"\\bteleportation\\s+protocol\\b\",\n",
    "        r\"\\bteleportation\\b\",\n",
    "    ]),\n",
    "    (\"Grover Search\", [\n",
    "        r\"\\bgrover('?s)?\\b\",\n",
    "        r\"\\bgrover\\s+search\\b\",\n",
    "    ]),\n",
    "    (\"Quantum Fourier Transform\", [\n",
    "        r\"\\bquantum\\s+fourier\\s+transform\\b\",\n",
    "        r\"\\bqft\\b\",\n",
    "    ]),\n",
    "    (\"Phase Estimation\", [\n",
    "        r\"\\bquantum\\s+phase\\s+estimation\\b\",\n",
    "        r\"\\bphase\\s+estimation\\b\",\n",
    "        r\"\\bqpe\\b\",\n",
    "        r\"\\bpea\\b\",\n",
    "    ]),\n",
    "    (\"Shor's Algorithm\", [\n",
    "        r\"\\bshor('?s)?\\b\",\n",
    "        r\"\\bshor'?s\\s+algorithm\\b\",\n",
    "        r\"\\border\\s+finding\\b\",\n",
    "    ]),\n",
    "    (\"VQE\", [\n",
    "        r\"\\bvariational\\s+quantum\\s+eigensolver\\b\",\n",
    "        r\"\\bvqe\\b\",\n",
    "    ]),\n",
    "    (\"QAOA\", [\n",
    "        r\"\\bquantum\\s+approximate\\s+optimization\\s+algorithm\\b\",\n",
    "        r\"\\bqaoa\\b\",\n",
    "    ]),\n",
    "    (\"Quantum Error Correction\", [\n",
    "        r\"\\bquantum\\s+error\\s+correction\\b\",\n",
    "        r\"\\berror\\s+correction\\b\",\n",
    "        r\"\\bstabilizer\\b\",\n",
    "        r\"\\bsyndrome\\b\",\n",
    "        r\"\\bmagic\\s+state\\b\",\n",
    "        r\"\\bdistillation\\b\",\n",
    "    ]),\n",
    "    (\"Quantum Simulation\", [\n",
    "        r\"\\bquantum\\s+simulation\\b\",\n",
    "        r\"\\bhamiltonian\\s+simulation\\b\",\n",
    "        r\"\\btime\\s+evolution\\b\",\n",
    "        r\"\\btrotter\\b\",\n",
    "        r\"\\btrotterization\\b\",\n",
    "    ]),\n",
    "    (\"Variational / Ansatz Circuit\", [\n",
    "        r\"\\bansatz\\b\",\n",
    "        r\"\\bvariational\\b\",\n",
    "        r\"\\bparameteri[sz]ed\\b\",\n",
    "    ]),\n",
    "    (\"Deutsch‚ÄìJozsa\", [\n",
    "        r\"\\bdeutsch[-\\s]*jozsa\\b\",\n",
    "        r\"\\bdj\\s+algorithm\\b\",\n",
    "    ]),\n",
    "    (\"Bernstein‚ÄìVazirani\", [\n",
    "        r\"\\bbernstein[-\\s]*vazirani\\b\",\n",
    "        r\"\\bbv\\s+algorithm\\b\",\n",
    "    ]),\n",
    "    (\"Simon's Algorithm\", [\n",
    "        r\"\\bsimon('?s)?\\s+algorithm\\b\",\n",
    "        r\"\\bsimon\\b\",\n",
    "    ]),\n",
    "    (\"Amplitude Estimation\", [\n",
    "        r\"\\bamplitude\\s+estimation\\b\",\n",
    "        r\"\\bqae\\b\",\n",
    "    ]),\n",
    "    (\"HHL\", [\n",
    "        r\"\\bhhl\\b\",\n",
    "    ])\n",
    "]\n",
    "\n",
    "def detect_quantum_problem(descriptions, ocr_text=None):\n",
    "    combined = \" \".join(descriptions) if descriptions else \"\"\n",
    "    if ocr_text:\n",
    "        combined += \" \" + ocr_text\n",
    "\n",
    "    text = combined.lower()\n",
    "\n",
    "    for label, patterns in PROBLEM_PATTERNS:\n",
    "        for pat in patterns:\n",
    "            if re.search(pat, text, flags=re.IGNORECASE):\n",
    "                return label\n",
    "\n",
    "    return \"unspecified\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5f5bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving meta data and json and csv\n",
    "#Build Metadata Entry (2.3.7) demo code \n",
    "import os, re, csv, logging, time, random\n",
    "import json   # ‚Üê REQUIRED\n",
    "from pathlib import Path\n",
    "\n",
    "def build_metadata_entry(\n",
    "    image_filename,\n",
    "    arxiv_id,\n",
    "    page_number,\n",
    "    figure_number,\n",
    "    gates,\n",
    "    problem,\n",
    "    descriptions,\n",
    "    positions\n",
    "):\n",
    "    \"\"\"\n",
    "    Build the final metadata dict for one saved circuit image.\n",
    "    Ensures JSON-safe types (e.g., tuples -> lists).\n",
    "    \"\"\"\n",
    "    # Ensure correct types\n",
    "    gates = list(gates) if gates else []\n",
    "    descriptions = list(descriptions) if descriptions else []\n",
    "    \n",
    "    # positions should be list of [start, end]\n",
    "    fixed_positions = []\n",
    "    for pos in positions or []:\n",
    "        if isinstance(pos, tuple):\n",
    "            fixed_positions.append([int(pos[0]), int(pos[1])])\n",
    "        else:\n",
    "            fixed_positions.append([int(pos[0]), int(pos[1])])\n",
    "\n",
    "    # Make sure descriptions and positions lengths match\n",
    "    if len(descriptions) != len(fixed_positions):\n",
    "        # safest fallback: drop both to avoid invalid dataset\n",
    "        descriptions = []\n",
    "        fixed_positions = []\n",
    "\n",
    "    return {\n",
    "        \"image_filename\": image_filename,\n",
    "        \"arxiv_number\": arxiv_id,\n",
    "        \"page_number\": int(page_number),\n",
    "        \"figure_number\": figure_number,  # may be None or string\n",
    "        \"quantum_gates\": gates,\n",
    "        \"quantum_problem\": problem if problem else \"unspecified\",\n",
    "        \"descriptions\": descriptions,\n",
    "        \"text_positions\": fixed_positions\n",
    "    }\n",
    "#JSON & CSV Writers (3.1, 3.2) demo code \n",
    "def save_dataset_json(entries, out_path=DATASET_JSON_PATH):\n",
    "    \"\"\"\n",
    "    Save all metadata entries to dataset_5.json.\n",
    "    \"\"\"\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(entries, f, indent=4, ensure_ascii=False)\n",
    "    log(f\"[INFO] Wrote dataset JSON ‚Üí {out_path}\")\n",
    "\n",
    "def save_counts_csv(paper_ids, paper_counts, out_path=COUNTS_CSV_PATH):\n",
    "    \"\"\"\n",
    "    Save per-paper image counts to paper_list_counts_5.csv.\n",
    "\n",
    "    Rules:\n",
    "    - For inspected papers: write count (including 0)\n",
    "    - For uninspected papers: leave blank\n",
    "    \"\"\"\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(out_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"paper_id\", \"num_images\"])\n",
    "\n",
    "        for pid in paper_ids:\n",
    "            if pid in paper_counts:\n",
    "                writer.writerow([pid, paper_counts[pid]])   # inspected\n",
    "            else:\n",
    "                writer.writerow([pid, \"\"])                  # uninspected (blank)\n",
    "\n",
    "    log(f\"[INFO] Wrote counts CSV ‚Üí {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc13cb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import fitz\n",
    "\n",
    "def compute_color_score(pix: fitz.Pixmap, debug=False) -> float:\n",
    "    \"\"\"\n",
    "    Compute a color score for a pixmap, indicating visual complexity.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pix : fitz.Pixmap\n",
    "        A PyMuPDF Pixmap object (from PDF).\n",
    "    debug : bool\n",
    "        If True, also return intermediate values (for tuning)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Final score between 0.0 and 1.0 (high = complex image)\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Convert pixmap to RGB numpy image ---\n",
    "    img = np.frombuffer(pix.samples, dtype=np.uint8)\n",
    "    img = img.reshape(pix.height, pix.width, pix.n)\n",
    "    if img.shape[2] > 3:\n",
    "        img = img[:, :, :3]  # strip alpha\n",
    "\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # --- Unique colors ---\n",
    "    unique_colors = len(np.unique(img.reshape(-1, 3), axis=0))\n",
    "\n",
    "    # --- Curve ratio ---\n",
    "    edges = cv2.Canny(gray, 50, 150)\n",
    "    total_edge_pixels = np.sum(edges > 0)\n",
    "\n",
    "    lines = cv2.HoughLinesP(\n",
    "        edges, 1, np.pi / 180,\n",
    "        threshold=150,\n",
    "        minLineLength=40,\n",
    "        maxLineGap=5\n",
    "    )\n",
    "\n",
    "    def straight_line_pixel_count(lines):\n",
    "        if lines is None:\n",
    "            return 0\n",
    "        return sum(np.sqrt((x2 - x1)**2 + (y2 - y1)**2) for [[x1, y1, x2, y2]] in lines)\n",
    "\n",
    "    straight_pixels = straight_line_pixel_count(lines)\n",
    "    curve_ratio = 1.0 - (straight_pixels / total_edge_pixels) if total_edge_pixels > 0 else 0.0\n",
    "\n",
    "    # --- Better normalization ranges (tighter) ---\n",
    "    def normalize(val, low, high):\n",
    "        return min(max((val - low) / (high - low), 0.0), 1.0)\n",
    "\n",
    "    # Aggressively penalize colorful and curvy diagrams\n",
    "    norm_color = normalize(unique_colors, low=300, high=1200)     # more sensitive\n",
    "    norm_curve = normalize(curve_ratio, low=0.2, high=0.5)         # curves matter earlier\n",
    "\n",
    "    # Combine with higher weight for curves\n",
    "    color_score = 0.4 * norm_color + 0.6 * norm_curve\n",
    "\n",
    "    if debug:\n",
    "        return round(color_score, 3)\n",
    "\n",
    "    return round(color_score, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fcbceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "\n",
    "def compute_text_object_ratio(pix: fitz.Pixmap) -> float:\n",
    "    \"\"\"\n",
    "    Computes the ratio between text (OCR) and objects (lines, shapes) in a given pix image.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    pix : fitz.Pixmap\n",
    "        A PyMuPDF Pixmap image object.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    ratio : float\n",
    "        Ratio of total text area to total object area. Returns -1 if nothing detected.\n",
    "    \"\"\"\n",
    "    # 1. Convert Pixmap to PIL Image\n",
    "    img_mode = \"RGB\" if pix.n < 4 else \"RGBA\"\n",
    "    pil_img = Image.frombytes(img_mode, [pix.width, pix.height], pix.samples)\n",
    "    img = np.array(pil_img.convert(\"RGB\"))\n",
    "\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "\n",
    "    # 2. OCR text detection (bounding boxes)\n",
    "    data = pytesseract.image_to_data(pil_img, output_type=pytesseract.Output.DICT)\n",
    "    text_area = 0\n",
    "    for i in range(len(data[\"text\"])):\n",
    "        if int(data[\"conf\"][i]) > 30:  # confidence threshold\n",
    "            (w, h) = (int(data[\"width\"][i]), int(data[\"height\"][i]))\n",
    "            text_area += w * h\n",
    "\n",
    "    # 3. Object detection (contours)\n",
    "    edged = cv2.Canny(blurred, 50, 150)\n",
    "    contours, _ = cv2.findContours(edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    object_area = 0\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area > 10:  # ignore small noise\n",
    "            object_area += area\n",
    "\n",
    "    # 4. Compute ratio\n",
    "    if object_area == 0:\n",
    "        return -1  # avoid division by zero\n",
    "    return round(text_area / object_area, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e47ccc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline():\n",
    "    \"\"\"\n",
    "    Main processing loop (RASTER ONLY).\n",
    "\n",
    "    - Iterates over papers in paper_list_5.txt (in order)\n",
    "    - Downloads each PDF (if needed)\n",
    "    - Extracts raster image candidates\n",
    "    - Classifies them with is_raster_circuit_image(pixmap, page_text)\n",
    "    - Saves only accepted circuit images as PNGs\n",
    "    - Builds metadata entries for each accepted image\n",
    "    - Writes dataset_5.json and paper_list_counts_5.csv\n",
    "\n",
    "    Uses:\n",
    "    - MAX_IMAGES, IMAGE_DIR, DATASET_JSON_PATH, COUNTS_CSV_PATH\n",
    "    - load_paper_list, download_pdf, extract_full_text, extract_images_from_pdf\n",
    "    - is_raster_circuit_image, infer_figure_number_from_page, find_descriptions_for_figure\n",
    "    - detect_quantum_gates, detect_quantum_problem\n",
    "    - build_metadata_entry, save_pixmap_as_png, save_dataset_json, save_counts_csv\n",
    "    \"\"\"\n",
    "\n",
    "    paper_ids = load_paper_list()\n",
    "    paper_counts = {}       # arxiv_id -> number of accepted circuit images\n",
    "    dataset_entries = []    # list of metadata dicts\n",
    "\n",
    "    total_circuit_images = 0\n",
    "    next_image_index = 1\n",
    "\n",
    "    log(f\"[INFO] Starting RASTER pipeline. Target MAX_IMAGES={MAX_IMAGES}\")\n",
    "    log(f\"[INFO] Papers in list: {len(paper_ids)}\")\n",
    "\n",
    "    for arxiv_id in paper_ids:\n",
    "        # Global stopping condition\n",
    "        if total_circuit_images >= MAX_IMAGES:\n",
    "            log(\"[INFO] Reached MAX_IMAGES. Stopping.\")\n",
    "            break\n",
    "\n",
    "        log(f\"[INFO] Processing paper {arxiv_id}\")\n",
    "        num_circuits_in_paper = 0\n",
    "\n",
    "        # -----------------------------\n",
    "        # 1) Download / open PDF\n",
    "        # -----------------------------\n",
    "        pdf_path = download_pdf(arxiv_id)\n",
    "        if pdf_path is None:\n",
    "            log(f\"[WARN] Skipping {arxiv_id} (PDF download failed).\")\n",
    "            paper_counts[arxiv_id] = 0\n",
    "            continue\n",
    "\n",
    "        # -----------------------------\n",
    "        # 2) Extract text once (full + per-page)\n",
    "        # -----------------------------\n",
    "        try:\n",
    "            full_text, page_texts = extract_full_text(pdf_path)\n",
    "        except Exception as e:\n",
    "            log(f\"[ERROR] Text extraction failed for {arxiv_id}: {e}\",\n",
    "                logfile=\"parsing_errors.log\")\n",
    "            paper_counts[arxiv_id] = 0\n",
    "            continue\n",
    "\n",
    "        page_text_dict = {p: t for p, t in page_texts}\n",
    "\n",
    "        # -----------------------------\n",
    "        # 3) Extract raster image candidates\n",
    "        # -----------------------------\n",
    "        raster_images = extract_images_from_pdf(pdf_path)\n",
    "        log(f\"[DEBUG] {arxiv_id}: {len(raster_images)} raster image candidates\")\n",
    "\n",
    "        # -----------------------------\n",
    "        # 4) Classify & keep only circuits\n",
    "        # -----------------------------\n",
    "        for rec in raster_images:\n",
    "            if total_circuit_images >= MAX_IMAGES:\n",
    "                break\n",
    "\n",
    "            page_number = rec[\"page_number\"]\n",
    "            pixmap = rec[\"pixmap\"]\n",
    "            local_idx = rec[\"image_index\"]   # index of this image on the page\n",
    "\n",
    "            page_text = page_text_dict.get(page_number, \"\")\n",
    "\n",
    "            #SAME RASTER CLASSIFICATION AS TEST CODE\n",
    "            if not is_raster_circuit_image(pixmap, page_text):\n",
    "                continue  # reject non-circuit\n",
    "\n",
    "            # -----------------------------\n",
    "            # 5) Metadata: figure number, descriptions, positions\n",
    "            # -----------------------------\n",
    "            figure_number = infer_figure_number_from_page(page_text, local_idx)\n",
    "\n",
    "            descriptions, positions = [], []\n",
    "            if figure_number is not None:\n",
    "                descriptions, positions = find_descriptions_for_figure(\n",
    "                    full_text=full_text,\n",
    "                    page_texts=page_texts,\n",
    "                    page_number=page_number,\n",
    "                    figure_number=figure_number\n",
    "                )\n",
    "\n",
    "            gates = detect_quantum_gates(descriptions)\n",
    "            problem = detect_quantum_problem(descriptions)\n",
    "\n",
    "            # -----------------------------\n",
    "            # 6) Save image PNG\n",
    "            # -----------------------------\n",
    "            \n",
    "            color_score =  compute_color_score(pixmap)\n",
    "            img_ratio = compute_text_object_ratio(pixmap)\n",
    "            image_filename = f\"image_{next_image_index:04d}-{color_score}-{img_ratio}.png\"\n",
    "            if color_score < 0.685 and img_ratio < 2.6 :\n",
    "                save_pixmap_as_png(pixmap, image_filename, IMAGE_DIR)\n",
    "\n",
    "              \n",
    "          # 7) Build metadata entry\n",
    "                meta = build_metadata_entry(\n",
    "                    image_filename=image_filename,\n",
    "                    arxiv_id=arxiv_id,\n",
    "                    page_number=page_number,\n",
    "                    figure_number=figure_number,\n",
    "                    gates=gates,\n",
    "                    problem=problem,\n",
    "                    descriptions=descriptions,\n",
    "                    positions=positions\n",
    "                )\n",
    "                dataset_entries.append(meta)\n",
    "\n",
    "            # 8) Update counters\n",
    "                next_image_index += 1\n",
    "                total_circuit_images += 1\n",
    "                num_circuits_in_paper += 1\n",
    "                \n",
    "        paper_counts[arxiv_id] = num_circuits_in_paper\n",
    "        log(f\"[INFO] Paper {arxiv_id}: {num_circuits_in_paper} raster circuit images\")\n",
    "        # -----------------------------\n",
    "        # 3) Extract vector candidates\n",
    "        # -----------------------------\n",
    "      \n",
    "        # -----------------------------\n",
    "        # 3) Extract vector candidates\n",
    "        # -----------------------------\n",
    "        try:\n",
    "            # materialize generator for debugging\n",
    "            vector_recs = list(\n",
    "                extract_vector_circuit_images(pdf_path, full_text, page_texts)\n",
    "            )\n",
    "        except Exception as e:\n",
    "            log(\n",
    "                f\"[ERROR] Vector extraction failed for {arxiv_id}: {e}\",\n",
    "                logfile=\"parsing_errors.log\"\n",
    "            )\n",
    "            paper_counts[arxiv_id] = 0\n",
    "            continue\n",
    "\n",
    "        log(f\"[DEBUG] {arxiv_id}: {len(vector_recs)} raw vector candidates\")\n",
    "\n",
    "        # -----------------------------\n",
    "        # 4) Classify & keep only circuits\n",
    "        # -----------------------------\n",
    "        for i, vrec in enumerate(vector_recs):\n",
    "            if total_circuit_images >= MAX_IMAGES:\n",
    "                break\n",
    "\n",
    "            pixmap = vrec[\"pixmap\"]\n",
    "            img = pil_from_pixmap(pixmap)\n",
    "\n",
    "            page_number   = vrec[\"page_number\"]\n",
    "            figure_number = vrec.get(\"figure_number\")  # may be None\n",
    "            descriptions  = vrec.get(\"descriptions\", []) or []\n",
    "            positions     = vrec.get(\"positions\", []) or []\n",
    "\n",
    "            if not descriptions and figure_number is not None:\n",
    "                try:\n",
    "                    desc2, pos2 = find_descriptions_for_figure(\n",
    "                        full_text=full_text,\n",
    "                        page_texts=page_texts,\n",
    "                        page_number=page_number,\n",
    "                        figure_number=figure_number\n",
    "                    )\n",
    "                    if desc2:\n",
    "                        descriptions = desc2\n",
    "                        positions = pos2\n",
    "                except Exception as e:\n",
    "                    log(\n",
    "                        f\"[WARN] Description extraction failed for {arxiv_id} \"\n",
    "                        f\"page {page_number}, fig {figure_number}: {e}\",\n",
    "                        logfile=\"parsing_errors.log\"\n",
    "                    )\n",
    "            #if is_definitely_graph(img):\n",
    "             #   continue\n",
    "            if not is_vector_circuit_final(img, descriptions):\n",
    "                continue  # reject non-circuit\n",
    "\n",
    "            # 5) Gate + problem detection (OCR + captions)\n",
    "            gates, problem = semantic_info_from_image(pixmap, descriptions)\n",
    "\n",
    "            # 6) Save image PNG\n",
    "            color_score =  compute_color_score(pixmap)\n",
    "            img_ratio = compute_text_object_ratio(pixmap)\n",
    "            image_filename = f\"image_{next_image_index:04d}-{color_score}-{img_ratio}.png\"\n",
    "            if color_score < 0.685 and img_ratio < 2.6 :\n",
    "                save_pixmap_as_png(pixmap, image_filename, IMAGE_DIR)\n",
    "\n",
    "        # 7) Build metadata entry\n",
    "                meta = build_metadata_entry(\n",
    "                    image_filename=image_filename,\n",
    "                    arxiv_id=arxiv_id,\n",
    "                    page_number=page_number,\n",
    "                    figure_number=figure_number,\n",
    "                    gates=gates,\n",
    "                    problem=problem,\n",
    "                    descriptions=descriptions,\n",
    "                    positions=positions\n",
    "                )\n",
    "                dataset_entries.append(meta)\n",
    "\n",
    "            # 8) Update counters\n",
    "                next_image_index += 1\n",
    "                total_circuit_images += 1\n",
    "                num_circuits_in_paper += 1\n",
    "            \n",
    "\n",
    "\n",
    "        paper_counts[arxiv_id] = num_circuits_in_paper\n",
    "        log(f\"[INFO] Paper {arxiv_id}: {num_circuits_in_paper} vector circuit images\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # 9) Save outputs\n",
    "    # -----------------------------\n",
    "    save_dataset_json(dataset_entries)\n",
    "    save_counts_csv(paper_ids, paper_counts)\n",
    "    log(f\"[INFO] RASTER pipeline finished. Total images: {total_circuit_images}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c136f109",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    run_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04899dbb",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
